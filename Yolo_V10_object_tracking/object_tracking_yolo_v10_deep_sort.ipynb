{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8428ddc1-7ab6-4f8c-a344-5798d19d5c7e",
   "metadata": {},
   "source": [
    "# OBJECT TRACKING | YOLO v10 | Deep SORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a984b",
   "metadata": {},
   "source": [
    "# Content\n",
    "## 1. What is Deep Sort?\n",
    "## 2. Deep Sort Working.\n",
    "## 3. Inferencing using deep sort algorithm.\n",
    "## 4. Application using streamlit to track the objects in videos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477582a4-fc3f-499b-bf8a-6d436194c718",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164f2143-8362-4973-99e4-45a2b8d11ad3",
   "metadata": {},
   "source": [
    "# DeepSort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc161612-b3a7-43a4-87e7-0abe936cf490",
   "metadata": {},
   "source": [
    "### DeepSORT is a Computer Vision Tracking Algorithm used to track the objects while assigning each of the tracked object a unique id. DeepSORT is an extension of the SORT. DeepSORT introduces deep learning into SORT algorithm by adding appearance descriptor to reduce the identity switches and hence making the tracking more efficient.\n",
    "\n",
    "\n",
    "                                                         OR                                                     \n",
    "\n",
    "### DeepSORT can be defined as a tracking algorithm which tracks object not only based on the velocity and motion of the object but also based on the appearance of the object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec80116f-495c-466a-9391-f25d7d0d20cb",
   "metadata": {},
   "source": [
    "# DeepSort Working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c293f-312d-402c-b631-2fd694da3f9a",
   "metadata": {},
   "source": [
    "### Working\n",
    "\n",
    "#### SORT is an approach to object tracking where Kalman Filters and Hungarian Algorithms are used to track objects. SORT consists of four components which are as follows:\n",
    " 1. Detection\n",
    " 2. Estimation\n",
    " 3. Data Association\n",
    " 4. Creation and Deletion of Track Identities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a325921",
   "metadata": {},
   "source": [
    "### Detection: \n",
    "* As first step objects needs to be detect using Yolov10 (object detection model) so it can be tracked. Then these detectionsare passed to next step.\n",
    "### Estimation: \n",
    "* Here in this step we pass the detection from current frame to next frame to estimate the position of the target in the next frame using Gausian Distribution and constant velocity model. The estimation is done using the Kalman Filter.\n",
    "### Data Association: \n",
    "* We now have the target bounding box and the detected bounding box. So, a cost matrix is computed as the intersection-over-union (IOU) distance between each detection and all predicted bounding boxes from the existing targets.\n",
    "### Creation and deletion of track IDs: \n",
    "+ When any object is about to enter or exit the frame then unique object idâ€™s are created and destroyed accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e95dd",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2543c715",
   "metadata": {},
   "source": [
    "# *PROBLEM*\n",
    "- But there are two problems with Sort Algorithm\n",
    "1. Deficiency in tracking to occlusion/ fails in case of occlusion and different view points.\n",
    "2. Despite the effectiveness of Kalman filter, it returns a relatively higher number of ID switches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1f3611",
   "metadata": {},
   "source": [
    "# *SOLUTION* \n",
    "- These issues are because of the association metric used.\n",
    "\n",
    "- So, in DeepSORT we use another distance metric which is based on the appearance of the object. The appearance feature vector (Deep Appearance Descriptor).\n",
    "- DeepSORT uses a better association metrics which combines both motion and appearance descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674e6f49",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccd6465-41e1-45e2-bb85-224db86a603d",
   "metadata": {},
   "source": [
    "# INFERENCING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205f371b-dd36-428b-be2f-bc887b56fd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install ultralytics\n",
    "# ! pip install supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abefa376-9eaf-437a-bdb7-1f5e0b7a1916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLOv10\n",
    "import wget\n",
    "import numpy as np\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "import time\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d21fd98-d748-4d07-b411-339fd01b1d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 10% [.......                                                               ]  13123584 / 128288859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget.download('https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf635ae7-a67f-46e1-a477-1448e86165bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Roaming\\Python\\Python310\\site-packages\\ultralytics\\nn\\tasks.py:733: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ckpt = torch.load(file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model = YOLOv10('yolov10x.pt')\n",
    "\n",
    "deep_sort_weights = 'deep_sort/deep/checkpoint/ckpt.t7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4576f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(image, text, top_left, bottom_right, color, font_color, font_scale=0.6, font_thickness=2):\n",
    "    # Calculate text size\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "    \n",
    "    # Create a filled rectangle for text background\n",
    "    text_background_top_left = (top_left[0]+18, top_left[1] - text_size[1] - 10)\n",
    "    text_background_bottom_right = (top_left[0] + text_size[0] + 25, top_left[1])\n",
    "    \n",
    "    cv2.rectangle(image, text_background_top_left, text_background_bottom_right, color, cv2.FILLED)\n",
    "    \n",
    "    # Add text on top of the rectangle\n",
    "    text_position = (top_left[0] + 18, top_left[1] - 5)\n",
    "    cv2.putText(image, text, text_position, font, font_scale, font_color, font_thickness)\n",
    "\n",
    "def draw_rounded_rectangle(image, top_left, bottom_right, color, thickness, radius):\n",
    "    tl = (top_left[0] + radius, top_left[1] + radius)\n",
    "    tr = (bottom_right[0] - radius, top_left[1] + radius)\n",
    "    bl = (top_left[0] + radius, bottom_right[1] - radius)\n",
    "    br = (bottom_right[0] - radius, bottom_right[1] - radius)\n",
    "    \n",
    "    # image=cv2.rectangle(image, p1, p2, color, thickness=lw, lineType=cv2.LINE_AA)\n",
    "\n",
    "    cv2.rectangle(image, (tl[0], top_left[1]), (tr[0], bottom_right[1]), color, 2, cv2.LINE_AA)\n",
    "    cv2.rectangle(image, (top_left[0], tl[1]), (bottom_right[0], bl[1]), color, thickness)\n",
    "    cv2.circle(image, tl, radius, color, thickness)\n",
    "    cv2.circle(image, tr, radius, color, thickness)\n",
    "    cv2.circle(image, bl, radius, color, thickness)\n",
    "    cv2.circle(image, br, radius, color, thickness)\n",
    "\n",
    "\n",
    "def draw_text(image, text, position, background_color, font_color, font_scale=0.5, font_thickness=1):\n",
    "    # Calculate text size\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "    \n",
    "    # Create a filled rectangle for text background\n",
    "    text_background_top_left = (position[0] - 5, position[1] + 5)\n",
    "    text_background_bottom_right = (position[0] + text_size[0] + 5, position[1] - text_size[1] - 5)\n",
    "    \n",
    "    cv2.rectangle(image, text_background_top_left, text_background_bottom_right, background_color, cv2.FILLED)\n",
    "    \n",
    "    # Add text on top of the rectangle\n",
    "    text_position = (position[0], position[1] - 5)\n",
    "    cv2.putText(image, text, text_position, font, font_scale, font_color, font_thickness)\n",
    "\n",
    "def get_box_details(boxes):\n",
    "    cls = boxes.cls.tolist()  # Convert tensor to list\n",
    "    xyxy = boxes.xyxy\n",
    "    conf = boxes.conf\n",
    "    xywh = boxes.xywh\n",
    "\n",
    "    return cls, xyxy, conf, xywh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4cbb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\youtube\\Computer-Vision-Projects\\Yolo_V10_object_tracking\\deep_sort\\deep\\feature_extractor.py:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=torch.device(self.device))[\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "\n",
      "0: 384x640 1 car, 397.8ms\n",
      "Speed: 249.4ms preprocess, 397.8ms inference, 74.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 236.3ms\n",
      "Speed: 22.4ms preprocess, 236.3ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 262.4ms\n",
      "Speed: 13.8ms preprocess, 262.4ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 182.5ms\n",
      "Speed: 13.8ms preprocess, 182.5ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 116.1ms\n",
      "Speed: 9.4ms preprocess, 116.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 113.0ms\n",
      "Speed: 10.1ms preprocess, 113.0ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 102.1ms\n",
      "Speed: 7.8ms preprocess, 102.1ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 106.7ms\n",
      "Speed: 12.3ms preprocess, 106.7ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 104.0ms\n",
      "Speed: 5.5ms preprocess, 104.0ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 car, 84.5ms\n",
      "Speed: 4.8ms preprocess, 84.5ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 94.8ms\n",
      "Speed: 11.6ms preprocess, 94.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 69.3ms\n",
      "Speed: 5.2ms preprocess, 69.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 95.8ms\n",
      "Speed: 8.5ms preprocess, 95.8ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 82.6ms\n",
      "Speed: 11.6ms preprocess, 82.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 94.0ms\n",
      "Speed: 9.0ms preprocess, 94.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 64.8ms\n",
      "Speed: 6.7ms preprocess, 64.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 65.0ms\n",
      "Speed: 5.2ms preprocess, 65.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 65.6ms\n",
      "Speed: 7.8ms preprocess, 65.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 63.2ms\n",
      "Speed: 7.5ms preprocess, 63.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 68.2ms\n",
      "Speed: 5.2ms preprocess, 68.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 77.9ms\n",
      "Speed: 4.5ms preprocess, 77.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.5ms\n",
      "Speed: 7.7ms preprocess, 61.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.7ms\n",
      "Speed: 6.4ms preprocess, 60.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.1ms\n",
      "Speed: 6.2ms preprocess, 61.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.9ms\n",
      "Speed: 6.1ms preprocess, 60.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 73.5ms\n",
      "Speed: 5.3ms preprocess, 73.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.5ms\n",
      "Speed: 7.8ms preprocess, 60.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.3ms\n",
      "Speed: 4.5ms preprocess, 60.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.2ms\n",
      "Speed: 7.4ms preprocess, 61.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 81.8ms\n",
      "Speed: 7.5ms preprocess, 81.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.2ms\n",
      "Speed: 6.2ms preprocess, 61.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.0ms\n",
      "Speed: 4.5ms preprocess, 61.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 64.9ms\n",
      "Speed: 7.2ms preprocess, 64.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 79.9ms\n",
      "Speed: 6.3ms preprocess, 79.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 89.4ms\n",
      "Speed: 8.3ms preprocess, 89.4ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 62.7ms\n",
      "Speed: 5.2ms preprocess, 62.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.1ms\n",
      "Speed: 6.3ms preprocess, 60.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 81.9ms\n",
      "Speed: 6.2ms preprocess, 81.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 64.4ms\n",
      "Speed: 7.2ms preprocess, 64.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 74.9ms\n",
      "Speed: 7.5ms preprocess, 74.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.3ms\n",
      "Speed: 4.1ms preprocess, 61.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 72.5ms\n",
      "Speed: 7.1ms preprocess, 72.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 65.6ms\n",
      "Speed: 5.2ms preprocess, 65.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 59.7ms\n",
      "Speed: 9.3ms preprocess, 59.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 66.4ms\n",
      "Speed: 6.0ms preprocess, 66.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 63.2ms\n",
      "Speed: 3.7ms preprocess, 63.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 66.7ms\n",
      "Speed: 4.0ms preprocess, 66.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 69.1ms\n",
      "Speed: 3.7ms preprocess, 69.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 67.9ms\n",
      "Speed: 7.8ms preprocess, 67.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 68.7ms\n",
      "Speed: 3.7ms preprocess, 68.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 60.7ms\n",
      "Speed: 3.8ms preprocess, 60.7ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 62.7ms\n",
      "Speed: 4.8ms preprocess, 62.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.1ms\n",
      "Speed: 5.8ms preprocess, 61.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 61.2ms\n",
      "Speed: 4.4ms preprocess, 61.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 78.3ms\n",
      "Speed: 7.8ms preprocess, 78.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 63.6ms\n",
      "Speed: 4.5ms preprocess, 63.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 76.2ms\n",
      "Speed: 5.5ms preprocess, 76.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 86.3ms\n",
      "Speed: 8.5ms preprocess, 86.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.7ms\n",
      "Speed: 6.8ms preprocess, 91.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 103.7ms\n",
      "Speed: 5.5ms preprocess, 103.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 73.7ms\n",
      "Speed: 8.6ms preprocess, 73.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 70.0ms\n",
      "Speed: 7.0ms preprocess, 70.0ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 77.0ms\n",
      "Speed: 4.5ms preprocess, 77.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 72.9ms\n",
      "Speed: 7.0ms preprocess, 72.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 77.9ms\n",
      "Speed: 10.1ms preprocess, 77.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 73.3ms\n",
      "Speed: 5.3ms preprocess, 73.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 89.6ms\n",
      "Speed: 8.5ms preprocess, 89.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 67.7ms\n",
      "Speed: 6.2ms preprocess, 67.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 81.5ms\n",
      "Speed: 6.3ms preprocess, 81.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 72.4ms\n",
      "Speed: 8.5ms preprocess, 72.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 72.6ms\n",
      "Speed: 7.5ms preprocess, 72.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 70.9ms\n",
      "Speed: 5.3ms preprocess, 70.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 79.8ms\n",
      "Speed: 6.0ms preprocess, 79.8ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 75.8ms\n",
      "Speed: 7.8ms preprocess, 75.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 69.9ms\n",
      "Speed: 7.5ms preprocess, 69.9ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 70.6ms\n",
      "Speed: 8.2ms preprocess, 70.6ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 77.3ms\n",
      "Speed: 7.6ms preprocess, 77.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 64.9ms\n",
      "Speed: 7.8ms preprocess, 64.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 95.4ms\n",
      "Speed: 6.7ms preprocess, 95.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 82.4ms\n",
      "Speed: 8.5ms preprocess, 82.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 71.5ms\n",
      "Speed: 7.5ms preprocess, 71.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 67.7ms\n",
      "Speed: 6.8ms preprocess, 67.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 69.4ms\n",
      "Speed: 5.1ms preprocess, 69.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 66.4ms\n",
      "Speed: 7.0ms preprocess, 66.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 71.3ms\n",
      "Speed: 8.3ms preprocess, 71.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 79.2ms\n",
      "Speed: 6.7ms preprocess, 79.2ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 102.7ms\n",
      "Speed: 9.0ms preprocess, 102.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 80.0ms\n",
      "Speed: 9.8ms preprocess, 80.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.6ms\n",
      "Speed: 7.6ms preprocess, 91.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 75.0ms\n",
      "Speed: 6.7ms preprocess, 75.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.5ms\n",
      "Speed: 6.3ms preprocess, 91.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 79.1ms\n",
      "Speed: 6.3ms preprocess, 79.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 68.5ms\n",
      "Speed: 6.8ms preprocess, 68.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 75.7ms\n",
      "Speed: 5.2ms preprocess, 75.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 86.6ms\n",
      "Speed: 5.3ms preprocess, 86.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 77.1ms\n",
      "Speed: 7.5ms preprocess, 77.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 87.7ms\n",
      "Speed: 6.3ms preprocess, 87.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 100.8ms\n",
      "Speed: 9.1ms preprocess, 100.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 93.8ms\n",
      "Speed: 6.3ms preprocess, 93.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 109.6ms\n",
      "Speed: 6.0ms preprocess, 109.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 100.0ms\n",
      "Speed: 6.0ms preprocess, 100.0ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.6ms\n",
      "Speed: 8.5ms preprocess, 91.6ms inference, 12.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 82.8ms\n",
      "Speed: 7.9ms preprocess, 82.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 90.6ms\n",
      "Speed: 10.1ms preprocess, 90.6ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.1ms\n",
      "Speed: 6.0ms preprocess, 91.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 80.8ms\n",
      "Speed: 7.0ms preprocess, 80.8ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 94.7ms\n",
      "Speed: 7.8ms preprocess, 94.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 87.8ms\n",
      "Speed: 10.0ms preprocess, 87.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 80.0ms\n",
      "Speed: 7.5ms preprocess, 80.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 88.4ms\n",
      "Speed: 7.8ms preprocess, 88.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 90.4ms\n",
      "Speed: 7.0ms preprocess, 90.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 95.2ms\n",
      "Speed: 6.6ms preprocess, 95.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 97.6ms\n",
      "Speed: 6.7ms preprocess, 97.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.7ms\n",
      "Speed: 6.7ms preprocess, 91.7ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 87.3ms\n",
      "Speed: 7.8ms preprocess, 87.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 79.6ms\n",
      "Speed: 7.0ms preprocess, 79.6ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 94.8ms\n",
      "Speed: 8.6ms preprocess, 94.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 89.8ms\n",
      "Speed: 8.2ms preprocess, 89.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 86.2ms\n",
      "Speed: 6.3ms preprocess, 86.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 87.2ms\n",
      "Speed: 6.7ms preprocess, 87.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 129.1ms\n",
      "Speed: 6.2ms preprocess, 129.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 84.7ms\n",
      "Speed: 7.1ms preprocess, 84.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 93.4ms\n",
      "Speed: 8.1ms preprocess, 93.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 91.0ms\n",
      "Speed: 9.1ms preprocess, 91.0ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 107.6ms\n",
      "Speed: 8.3ms preprocess, 107.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 76.5ms\n",
      "Speed: 5.8ms preprocess, 76.5ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 87.5ms\n",
      "Speed: 7.8ms preprocess, 87.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 93.3ms\n",
      "Speed: 5.6ms preprocess, 93.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 90.8ms\n",
      "Speed: 9.4ms preprocess, 90.8ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 113.1ms\n",
      "Speed: 7.0ms preprocess, 113.1ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 cell phone, 93.0ms\n",
      "Speed: 7.0ms preprocess, 93.0ms inference, 12.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 97.8ms\n",
      "Speed: 7.1ms preprocess, 97.8ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 cell phone, 97.0ms\n",
      "Speed: 7.2ms preprocess, 97.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 84.7ms\n",
      "Speed: 11.6ms preprocess, 84.7ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 110.1ms\n",
      "Speed: 10.6ms preprocess, 110.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 77.9ms\n",
      "Speed: 10.8ms preprocess, 77.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 101.0ms\n",
      "Speed: 7.5ms preprocess, 101.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 107.4ms\n",
      "Speed: 7.4ms preprocess, 107.4ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 86.6ms\n",
      "Speed: 7.9ms preprocess, 86.6ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 92.2ms\n",
      "Speed: 5.5ms preprocess, 92.2ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 90.9ms\n",
      "Speed: 9.0ms preprocess, 90.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 85.4ms\n",
      "Speed: 6.0ms preprocess, 85.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 82.2ms\n",
      "Speed: 6.2ms preprocess, 82.2ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 99.9ms\n",
      "Speed: 9.3ms preprocess, 99.9ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 109.1ms\n",
      "Speed: 8.3ms preprocess, 109.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 107.8ms\n",
      "Speed: 10.0ms preprocess, 107.8ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 101.1ms\n",
      "Speed: 7.0ms preprocess, 101.1ms inference, 9.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 101.9ms\n",
      "Speed: 5.2ms preprocess, 101.9ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 88.7ms\n",
      "Speed: 6.7ms preprocess, 88.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 98.5ms\n",
      "Speed: 7.1ms preprocess, 98.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 124.4ms\n",
      "Speed: 7.5ms preprocess, 124.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 100.8ms\n",
      "Speed: 6.9ms preprocess, 100.8ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 117.3ms\n",
      "Speed: 8.6ms preprocess, 117.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 89.0ms\n",
      "Speed: 7.1ms preprocess, 89.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 84.8ms\n",
      "Speed: 8.6ms preprocess, 84.8ms inference, 9.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 105.2ms\n",
      "Speed: 6.4ms preprocess, 105.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 2 persons, 1 car, 1 bench, 92.2ms\n",
      "Speed: 8.5ms preprocess, 92.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 106.1ms\n",
      "Speed: 7.8ms preprocess, 106.1ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 100.7ms\n",
      "Speed: 6.3ms preprocess, 100.7ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 90.7ms\n",
      "Speed: 7.5ms preprocess, 90.7ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 110.7ms\n",
      "Speed: 9.3ms preprocess, 110.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 99.2ms\n",
      "Speed: 6.3ms preprocess, 99.2ms inference, 10.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 122.1ms\n",
      "Speed: 6.2ms preprocess, 122.1ms inference, 11.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 95.4ms\n",
      "Speed: 7.0ms preprocess, 95.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 93.5ms\n",
      "Speed: 7.8ms preprocess, 93.5ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 99.4ms\n",
      "Speed: 9.0ms preprocess, 99.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 83.3ms\n",
      "Speed: 5.6ms preprocess, 83.3ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 104.7ms\n",
      "Speed: 7.0ms preprocess, 104.7ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 128.9ms\n",
      "Speed: 6.7ms preprocess, 128.9ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 93.9ms\n",
      "Speed: 10.8ms preprocess, 93.9ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "here\n",
      "\n",
      "0: 384x640 1 person, 1 car, 1 bench, 79.7ms\n",
      "Speed: 9.3ms preprocess, 79.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('4159610-hd_1920_1080_24fps.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "tracker = DeepSort(model_path=deep_sort_weights, max_age=70, n_init=5, max_iou_distance=0.8)\n",
    "\n",
    "details = []\n",
    "prev_details = {}\n",
    "frames = []\n",
    "unique_track_ids = set()\n",
    "frame_no = 0\n",
    "\n",
    "i = 0\n",
    "counter, fps, elapsed = 0, 0, 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        print('here')\n",
    "        og_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = og_frame.copy()\n",
    "\n",
    "        results = model(frame)\n",
    "\n",
    "        bboxes_xywh = []\n",
    "        confs = []\n",
    "\n",
    "        class_names = list(model.names.values())\n",
    "        cls, xyxy, conf, xywh = get_box_details(results[0].boxes) # type: ignore\n",
    "\n",
    "        for c, b, co in zip(cls, xywh, conf.cpu().numpy()):\n",
    "            if class_names[int(c)] == 'car' and co >=0.4:\n",
    "                bboxes_xywh.append(b.cpu().numpy())\n",
    "                confs.append(co)\n",
    "\n",
    "        bboxes_xywh = np.array(bboxes_xywh, dtype=float)\n",
    "\n",
    "        tracks = tracker.update(bboxes_xywh, confs, og_frame)\n",
    "        \n",
    "        ids = []\n",
    "        for track in tracker.tracker.tracks:\n",
    "            track_id = track.track_id\n",
    "            hits = track.hits\n",
    "            x1, y1, x2, y2 = track.to_tlbr()  # Get bounding box coordinates in (x1, y1, x2, y2) format\n",
    "            w = x2 - x1  # Calculate width\n",
    "            h = y2 - y1  # Calculate height\n",
    "\n",
    "            # Set color values for red, blue, and green\n",
    "            red_color = (0, 0, 255)  # (B, G, R)\n",
    "            blue_color = (255, 0, 0)  # (B, G, R)\n",
    "            green_color = (0, 255, 0)  # (B, G, R)\n",
    "\n",
    "            # Determine color based on track_id\n",
    "            color_id = track_id % 3\n",
    "            if color_id == 0:\n",
    "                color = red_color\n",
    "            elif color_id == 1:\n",
    "                color = blue_color\n",
    "            else:\n",
    "                color = green_color\n",
    "\n",
    "            draw_rounded_rectangle(og_frame, (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, 1, 15) # type: ignore\n",
    "\n",
    "            text_color = (255, 255, 255)  # Black color for text\n",
    "            draw_label(og_frame, f\"{'car'}-{track_id}\", (int(x1), int(y1)), (int(x1 + w), int(y1 + h)), color, text_color) # type: ignore\n",
    "            \n",
    "            if track_id not in prev_details:\n",
    "                prev_details[track_id] = [time.time(), color]           \n",
    "\n",
    "            # Add the track_id to the set of unique track IDs\n",
    "            unique_track_ids.add(track_id)\n",
    "            ids.append(track_id)\n",
    "    \n",
    "        prev_ids = list(prev_details.keys())\n",
    "        ids_done = set(prev_ids)^set(ids)\n",
    "        \n",
    "        # Update the person count based on the number of unique track IDs\n",
    "        object_counts = len(unique_track_ids)\n",
    "\n",
    "        for id in ids_done:\n",
    "            details.append(['car', id, time.time() - prev_details[id][0], prev_details[id][1], frame_no-1])\n",
    "            del prev_details[id]\n",
    "                           \n",
    "        # Update FPS and place on frame\n",
    "        current_time = time.perf_counter()\n",
    "        elapsed = (current_time - start_time)\n",
    "        counter += 1\n",
    "        if elapsed > 1:\n",
    "            fps = counter / elapsed\n",
    "            counter = 0\n",
    "            start_time = current_time\n",
    "\n",
    "        # Draw person count on frame\n",
    "        og_frame = cv2.cvtColor(og_frame, cv2.COLOR_BGR2RGB)\n",
    "        og_frame = cv2.resize(og_frame, (700, 600))\n",
    "\n",
    "        font_color = (255, 255, 255)  # White font\n",
    "\n",
    "        # Position to draw the text (bottom-left corner)\n",
    "        position = (10, 30)\n",
    "        background_color = (0, 0, 0)\n",
    "        timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        text = f'Frame: {frame_no} | Time: {timestamp} | Count: {object_counts}'\n",
    "        # # Draw the text on the image\n",
    "        draw_text(og_frame, text, position, background_color, font_color)\n",
    "\n",
    "        frame_no += 1\n",
    "\n",
    "        # Write the frame to the output video file\n",
    "        # out.write(cv2.cvtColor(og_frame, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Video\", og_frame)\n",
    "        # cv2.waitKey(0)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "# out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf93b2-042a-4b8a-878f-42a599848ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734db61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b06b94b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture('854671-hd_1920_1080_25fps.mp4')\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_path = 'output.mp4'\n",
    "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    out.write(frame)\n",
    "    \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
